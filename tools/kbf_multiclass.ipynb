{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: unsafe repository ('/MS3D' is owned by someone else)\n",
      "To add an exception for this directory, call:\n",
      "\n",
      "\tgit config --global --add safe.directory /MS3D\n",
      "2023-05-22 06:36:05,109   INFO  Loading Waymo dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 06:36:07,406   INFO  Total skipped info 0\n",
      "2023-05-22 06:36:07,407   INFO  Total samples for Waymo dataset: 37680\n",
      "2023-05-22 06:36:07,420   INFO  Total sampled samples for Waymo dataset: 18840\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/MS3D')\n",
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.utils import common_utils\n",
    "from pcdet.datasets import build_dataloader\n",
    "\n",
    "def pretty_print(ap_dict):\n",
    "    item_key = 'SOURCE\\tTARGET\\tMODEL\\t'\n",
    "    item_res = f'{cfg.DATA_CONFIG.DATASET.replace(\"Dataset\",\"\")}\\t{cfg.DATA_CONFIG_TAR.DATASET.replace(\"Dataset\",\"\")}\\t{cfg.MODEL.NAME}\\t'\n",
    "    for k,v in ap_dict.items():\n",
    "        if ('VEHICLE' in k) or ('PEDESTRIAN' in k) or ('CYCLIST' in k):\n",
    "            key = k[11:].replace('LEVEL_','L').replace('PEDESTRIAN','PED').replace('VEHICLE','VEH').replace('CYCLIST','CYC').replace(' ','')\n",
    "            item_key += f'{key}\\t'\n",
    "            item_res += f'{ap_dict[k][0]*100:0.2f}\\t'\n",
    "    item_key += '\\n'\n",
    "    item_res += '\\n'\n",
    "    print(item_key)\n",
    "    print(item_res)\n",
    "\n",
    "cfg_file = '/MS3D/tools/cfgs/target_waymo/ms3d_nuscenes_voxel_rcnn_centerhead.yaml'\n",
    "\n",
    "# Get target dataset\n",
    "cfg_from_yaml_file(cfg_file, cfg)\n",
    "logger = common_utils.create_logger('temp.txt', rank=cfg.LOCAL_RANK)\n",
    "if cfg.get('DATA_CONFIG_TAR', False):\n",
    "    dataset_cfg = cfg.DATA_CONFIG_TAR\n",
    "    classes = cfg.DATA_CONFIG_TAR.CLASS_NAMES\n",
    "    cfg.DATA_CONFIG_TAR.USE_PSEUDO_LABEL=False\n",
    "    if dataset_cfg.get('USE_TTA', False):\n",
    "        dataset_cfg.USE_TTA=False\n",
    "else:\n",
    "    dataset_cfg = cfg.DATA_CONFIG\n",
    "    classes = cfg.CLASS_NAMES\n",
    "dataset_cfg.DATA_SPLIT.test = 'train'\n",
    "dataset_cfg.USE_CUSTOM_TRAIN_SCENES = True\n",
    "dataset_cfg.SAMPLED_INTERVAL.test = 2\n",
    "\n",
    "target_set, _, _ = build_dataloader(\n",
    "            dataset_cfg=dataset_cfg,\n",
    "            class_names=classes,\n",
    "            batch_size=1, logger=logger, training=False, dist=False\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes: ['Vehicle', 'Vehicle', 'Vehicle', 'Cyclist', 'Cyclist', 'Pedestrian']\n",
      "Number of detectors:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aggregating_proposals: 100%|█████████████| 18840/18840 [01:13<00:00, 256.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from pcdet.utils import box_fusion_utils\n",
    "from tqdm import tqdm \n",
    "import numpy as np\n",
    "\n",
    "dets_txt = '/MS3D/tools/cfgs/target_waymo/kbf_combinations/pvrcnn_c.txt'\n",
    "print(f'classes: {cfg.DATA_CONFIG_TAR.CLASS_NAMES}')\n",
    "\n",
    "ps_dict = {}\n",
    "det_annos = box_fusion_utils.load_src_paths_txt(dets_txt)\n",
    "print('Number of detectors: ', len(det_annos))\n",
    "combined_dets = box_fusion_utils.combine_box_pkls(det_annos, score_th=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pcdet.utils import generate_ps_utils \n",
    "# generate_ps_utils.save_data(combined_dets, '/MS3D/tools/cfgs/target_waymo/kbf_combinations', \n",
    "#                             name=f\"vox_c_combined_dets.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task:\n",
    "1. Have diff discard/radius for diff classes\n",
    "Maybe something like this?\n",
    "```yaml\n",
    "# Check that all lists are same length\n",
    "classes: ['Vehicle', 'Vehicle', 'Vehicle', 'Cyclist', 'Cyclist', 'Pedestrian']\n",
    "discard: [4,4,4, 4,4, 4]\n",
    "radius: [2,2,2, 0.5,0.5, 0.3]\n",
    "```\n",
    "But if overlapping classes e.g. cyclist and pedestrian, you'd want the predominant class to be kept. Maybe it's okay to just match by class, then later on use NMS to keep the more confident classes?\n",
    "\n",
    "2. Weighing by detection quantity\n",
    "\n",
    "I wonder if there's some way to weigh by the number of detections it received? Low score but many detections make for a strong proposal.\n",
    "\n",
    "#### Comments\n",
    "Fine-tuning lyft -> waymo for ITSC submission was fine to use car,truck,bus -> vehicle,vehicle,vehicle. So I guess it doesn't affect the training to map it like this. I think it probably rendered the truck/bus heads useless since we labelled everything as 1 i.e. car. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find frames with the most cyclists and pedestrians\n",
    "num_cycs = {}\n",
    "num_peds = {}\n",
    "for enum, info in enumerate(target_set.infos):\n",
    "    num_cyc = np.count_nonzero(info['annos']['name'] == 'Cyclist')\n",
    "    num_ped = np.count_nonzero(info['annos']['name'] == 'Pedestrian')\n",
    "    seq_name = '_'.join(info['frame_id'].split('_')[:-1])\n",
    "    if seq_name not in num_cycs.keys():\n",
    "        num_cycs[seq_name] = 0\n",
    "    if seq_name not in num_peds.keys():\n",
    "        num_peds[seq_name] = 0\n",
    "    \n",
    "    num_cycs[seq_name] += num_cyc\n",
    "    num_peds[seq_name] += num_ped  \n",
    "sorted_num_peds = {k: v for k, v in sorted(num_peds.items(), key=lambda item: item[1], reverse=True)}\n",
    "sorted_num_cycs = {k: v for k, v in sorted(num_cycs.items(), key=lambda item: item[1], reverse=True)}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ped_seqs = list(sorted_num_peds.keys())[:100]\n",
    "cyc_seqs = list(sorted_num_cycs.keys())[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_combined_dets = []\n",
    "for frame in combined_dets:\n",
    "    seq_name = '_'.join(frame['frame_id'].split('_')[:-1])\n",
    "    if seq_name in cyc_seqs:\n",
    "        ds_combined_dets.append(frame)\n",
    "        \n",
    "ds_combined_dets = ds_combined_dets[::5]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: \n",
    "Have weights={}, weights['bw_c'], etc. where we specify an integer multiple of the src weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcdet.utils.box_fusion_utils import *\n",
    "\n",
    "def kde_fusion(boxes, src_weights, bw_c=1.0, bw_dim=2.0, bw_ry=0.1, bw_cls=0.5, bw_score=2.0):\n",
    "    \"\"\"\n",
    "    Combines the centroids, dims, ry and scores of multiple predicted boxes\n",
    "    Args:\n",
    "        boxes: (N,9) np array. Boxes for filtering\n",
    "        src_weights : (list). List of weights for each source detector\n",
    "\n",
    "    Returns:\n",
    "        combined box: (9) np array. A final box with params [x,y,z,dx,dy,dz,ry,score,class_id]\n",
    "\n",
    "    Centroids are selected rather than aggregated as aggregating can lead to odd centering\n",
    "    Rotations are selected as it is quite sensitive to aggregation\n",
    "    Dimensions/score are the peak value of the KDE since we want to factor in the sizing/cls conf of diff detectors                    \n",
    "    \"\"\"\n",
    "    def get_kde_value(data, src_weights, bw, return_max=False, verbose=False):\n",
    "        \"\"\"\n",
    "        If data points are too similar, KDE will fail. This is because\n",
    "        the covariance matrix is not invertible because the values are too close \n",
    "        (zero covriance on some diagonal elements).\n",
    "        \n",
    "        In these cases, we just take the weighted average.\n",
    "        \"\"\"\n",
    "        if return_max:\n",
    "            try:\n",
    "                _, new_val = get_kde(data, return_max=return_max, weights=src_weights, bw_method=bw)\n",
    "                return new_val\n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f'data:{data}, error:{e}')\n",
    "                return np.average(data, axis=0, weights=src_weights)\n",
    "        else:\n",
    "            try:\n",
    "                kde = get_kde(data, return_max=return_max, weights=src_weights, bw_method=bw)\n",
    "                new_inds = get_sample_inds_with_max_likelihood(data, kde)    \n",
    "                return new_inds\n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f'data:{data}, error:{e}')\n",
    "                return None\n",
    "        \n",
    "    centroids = boxes[:,:3]\n",
    "    det = np.linalg.det(np.cov(centroids.T, rowvar=1,bias=False))\n",
    "    if det < 1e-7:\n",
    "        new_cxy_inds = get_kde_value(centroids[:,:2], src_weights, bw_c, return_max=False)        \n",
    "        if new_cxy_inds is not None:\n",
    "            new_cxy = centroids[:,:2][new_cxy_inds]  \n",
    "        else:\n",
    "            new_cxy = np.average(centroids[:,:2], axis=0, weights=src_weights)\n",
    "              \n",
    "        new_cz_inds = get_kde_value(centroids[:,2], src_weights, bw_c, return_max=False)        \n",
    "        if new_cz_inds is not None:\n",
    "            new_cz = centroids[:,2][new_cz_inds]\n",
    "        else:\n",
    "            new_cz = np.average(centroids[:,2], axis=0, weights=src_weights)\n",
    "        \n",
    "        new_cxyz = np.hstack([new_cxy, new_cz])\n",
    "    else:\n",
    "        new_cxyz_inds = get_kde_value(centroids, src_weights, bw_c, return_max=False)\n",
    "        if new_cxyz_inds is not None:\n",
    "            new_cxyz = centroids[new_cxyz_inds]\n",
    "        else:\n",
    "            new_cxyz = np.average(centroids, axis=0, weights=src_weights)\n",
    "    \n",
    "    new_dx = get_kde_value(boxes[:,3], None, bw_dim, return_max=True)\n",
    "    new_dy = get_kde_value(boxes[:,4], None, bw_dim, return_max=True)\n",
    "    new_dz = get_kde_value(boxes[:,5], None, bw_dim, return_max=True)\n",
    "        \n",
    "    sin_rys = np.sin(boxes[:,6])\n",
    "    ry_ind = get_kde_value(sin_rys, src_weights, bw_ry, return_max=False)    \n",
    "    if ry_ind is not None:\n",
    "        new_ry = boxes[:,6][ry_ind]\n",
    "    else:\n",
    "        new_ry = get_rotation_near_weighted_mean(boxes[:,6])\n",
    "    \n",
    "\n",
    "    cls_ind = get_kde_value(boxes[:,7], src_weights, bw_cls, return_max=False)\n",
    "    if cls_ind is not None:\n",
    "        new_class = boxes[:,7][cls_ind]\n",
    "    else:\n",
    "        # Return majority class\n",
    "        unique, counts = np.unique(boxes[:,7], return_counts=True)\n",
    "        new_class = int(unique[np.argmax(counts)])\n",
    "    \n",
    "    new_score = get_kde_value(boxes[:,8], src_weights, bw_score, return_max=True)\n",
    "    \n",
    "    combined_box = np.hstack([new_cxyz[0], new_cxyz[1], new_cxyz[2], new_dx, new_dy, new_dz, new_ry, new_class, new_score])\n",
    "    return combined_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00: lyft_models.uda_voxel_rcnn_anchorhead.lyft10xyzt_waymo1xyzt_custom190_notta\n",
      "01: lyft_models.uda_voxel_rcnn_anchorhead.lyft10xyzt_waymo1xyzt_custom190_rwr\n",
      "02: lyft_models.uda_voxel_rcnn_anchorhead.lyft10xyzt_waymo1xyzt_custom190_rwf\n",
      "03: lyft_models.uda_voxel_rcnn_anchorhead.lyft10xyzt_waymo1xyzt_custom190_rwf_rwr\n",
      "04: lyft_models.uda_voxel_rcnn_anchorhead.lyft10xyzt_waymo2xyzt_custom190_notta\n",
      "05: lyft_models.uda_voxel_rcnn_anchorhead.lyft10xyzt_waymo2xyzt_custom190_rwr\n",
      "06: lyft_models.uda_voxel_rcnn_anchorhead.lyft10xyzt_waymo2xyzt_custom190_rwf\n",
      "07: lyft_models.uda_voxel_rcnn_anchorhead.lyft10xyzt_waymo2xyzt_custom190_rwf_rwr\n",
      "08: lyft_models.uda_voxel_rcnn_anchorhead.lyft10xyzt_waymo4xyzt_custom190_notta\n",
      "09: lyft_models.uda_voxel_rcnn_anchorhead.lyft10xyzt_waymo4xyzt_custom190_rwr\n",
      "10: lyft_models.uda_voxel_rcnn_anchorhead.lyft10xyzt_waymo4xyzt_custom190_rwf\n",
      "11: lyft_models.uda_voxel_rcnn_anchorhead.lyft10xyzt_waymo4xyzt_custom190_rwf_rwr\n",
      "12: lyft_models.uda_voxel_rcnn_centerhead.lyft10xyzt_waymo1xyzt_custom190_notta\n",
      "13: lyft_models.uda_voxel_rcnn_centerhead.lyft10xyzt_waymo1xyzt_custom190_rwr\n",
      "14: lyft_models.uda_voxel_rcnn_centerhead.lyft10xyzt_waymo1xyzt_custom190_rwf\n",
      "15: lyft_models.uda_voxel_rcnn_centerhead.lyft10xyzt_waymo1xyzt_custom190_rwf_rwr\n",
      "16: lyft_models.uda_voxel_rcnn_centerhead.lyft10xyzt_waymo2xyzt_custom190_notta\n",
      "17: lyft_models.uda_voxel_rcnn_centerhead.lyft10xyzt_waymo2xyzt_custom190_rwr\n",
      "18: lyft_models.uda_voxel_rcnn_centerhead.lyft10xyzt_waymo2xyzt_custom190_rwf\n",
      "19: lyft_models.uda_voxel_rcnn_centerhead.lyft10xyzt_waymo2xyzt_custom190_rwf_rwr\n",
      "20: lyft_models.uda_voxel_rcnn_centerhead.lyft10xyzt_waymo4xyzt_custom190_notta\n",
      "21: lyft_models.uda_voxel_rcnn_centerhead.lyft10xyzt_waymo4xyzt_custom190_rwr\n",
      "22: lyft_models.uda_voxel_rcnn_centerhead.lyft10xyzt_waymo4xyzt_custom190_rwf\n",
      "23: lyft_models.uda_voxel_rcnn_centerhead.lyft10xyzt_waymo4xyzt_custom190_rwf_rwr\n"
     ]
    }
   ],
   "source": [
    "for src_id, key in enumerate(det_annos.keys()):    \n",
    "    print(f'{src_id:02d}: {key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_fusion(boxes_lidar, fusion_name, discard, radius, nms_thresh=0.05):\n",
    "    \"\"\"\n",
    "    boxes_lidar (N,9): array of box proposals from src detectors\n",
    "    \n",
    "    return: \n",
    "        fused_boxes (N,9): fused box proposals\n",
    "    \"\"\"\n",
    "    matched_inds_list = get_matching_boxes(boxes_lidar, discard=discard, radius=radius)\n",
    "        \n",
    "    # Aggregate these into one box\n",
    "    combined_frame_boxes, num_matched_boxes = [], []\n",
    "    for m_box_inds in matched_inds_list:\n",
    "\n",
    "        matched_boxes = boxes_lidar[list(m_box_inds)]\n",
    "        unique = np.unique(matched_boxes[:,:3].round(decimals=4), axis=0)\n",
    "        if len(unique) < discard:\n",
    "            continue\n",
    "\n",
    "        src_weights = matched_boxes[:,8]                \n",
    "        combined_box = kde_fusion(matched_boxes, src_weights=src_weights)        \n",
    "        combined_frame_boxes.append(combined_box)\n",
    "        num_matched_boxes.append(len(unique))\n",
    "    \n",
    "    if combined_frame_boxes:\n",
    "        num_dets_per_box = np.array(num_matched_boxes)\n",
    "        fused_boxes = np.array(combined_frame_boxes)\n",
    "        nms_mask = nms(fused_boxes[:,:7], fused_boxes[:,8], thresh=nms_thresh)\n",
    "        fused_boxes = fused_boxes[nms_mask]\n",
    "        num_dets_per_box = num_dets_per_box[nms_mask]\n",
    "    else:\n",
    "        fused_boxes = np.empty((0,9))\n",
    "        num_dets_per_box = np.empty(0)\n",
    "        \n",
    "    return fused_boxes.astype(np.float32), num_dets_per_box.astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ps_dict(ds_combined_dets, classes, cls_kbf_config, scale_conf_by_ndets, detector_weights=None):\n",
    "    ps_dict = {}    \n",
    "    for frame_boxes in tqdm(ds_combined_dets, total=len(ds_combined_dets)):        \n",
    "            \n",
    "        boxes_lidar = np.hstack([frame_boxes['boxes_lidar'],\n",
    "                                 frame_boxes['class_ids'][...,np.newaxis],\n",
    "                                 frame_boxes['score'][...,np.newaxis]])\n",
    "        if detector_weights is not None:\n",
    "            box_weights = detector_weights['heading'][frame_boxes['source_id']]\n",
    "            boxes_lidar = np.hstack([boxes_lidar, box_weights[...,np.newaxis]])\n",
    "        \n",
    "        boxes_names = frame_boxes['names']\n",
    "        unique_classes = np.unique(boxes_names)    \n",
    "        ps_label_nms = []\n",
    "        for cls in unique_classes:\n",
    "            if cls not in classes:\n",
    "                continue\n",
    "            cls_mask = (boxes_names == cls)\n",
    "            cls_boxes = boxes_lidar[cls_mask]\n",
    "            score_mask = cls_boxes[:,8] > min_score\n",
    "            \n",
    "            cls_kbf_boxes, num_dets_per_box = label_fusion(cls_boxes, 'kde_fusion', \n",
    "                                           discard=cls_kbf_config[cls]['discard'], \n",
    "                                           radius=cls_kbf_config[cls]['radius'], \n",
    "                                           nms_thresh=cls_kbf_config[cls]['nms'], \n",
    "                                           weights=None)\n",
    "\n",
    "            # E.g. car,truck,bus,motorcycle,bicycle,pedestrian (id: 1,2,3,4,5,6) -> Veh,Cyc,Ped (id: 1,4,6)\n",
    "            cls_kbf_boxes[:,7] = cls_kbf_config[cls]['cls_id']\n",
    "\n",
    "            # Scale confidence score by number of detections\n",
    "            if scale_conf_by_ndets:\n",
    "                coeff = conf_scaling_coeff(num_dets_per_box, num_boxes_at_unity)\n",
    "                temp_frame_id = frame_boxes['frame_id']\n",
    "                mask = cls_kbf_boxes[:,8] < cfg.SELF_TRAIN.SCORE_THRESH\n",
    "                cls_kbf_boxes[mask,8] *= coeff[mask]\n",
    "                cls_kbf_boxes[mask,8] = np.clip(cls_kbf_boxes[mask,8], 0, max_scale_score)\n",
    "\n",
    "            ps_label_nms.extend(cls_kbf_boxes)\n",
    "\n",
    "        if ps_label_nms:\n",
    "            ps_label_nms = np.array(ps_label_nms)\n",
    "        else:\n",
    "            ps_label_nms = np.empty((0,9))\n",
    "\n",
    "        # neg_th < score < pos_th: ignore for training but keep for update step\n",
    "        pred_boxes = ps_label_nms[:,:7]\n",
    "        pred_labels = ps_label_nms[:,7]\n",
    "        pred_scores = ps_label_nms[:,8]\n",
    "        ignore_mask = pred_scores < cfg.SELF_TRAIN.SCORE_THRESH\n",
    "        pred_labels[ignore_mask] = -pred_labels[ignore_mask]\n",
    "        gt_box = np.concatenate((pred_boxes,\n",
    "                                pred_labels.reshape(-1, 1),\n",
    "                                pred_scores.reshape(-1, 1)), axis=1)    \n",
    "\n",
    "        gt_infos = {\n",
    "            'gt_boxes': gt_box,\n",
    "        }\n",
    "        ps_dict[frame_boxes['frame_id']] = gt_infos\n",
    "    \n",
    "    return ps_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                         | 1/1983 [00:00<00:02, 885.81it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "label_fusion() got an unexpected keyword argument 'weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23771/1539536003.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m ps_dict = get_ps_dict(ds_combined_dets, ['Cyclist'], cls_kbf_config, \n\u001b[0;32m---> 30\u001b[0;31m                       scale_conf_by_ndets=scale_conf_by_ndets, detector_weights=detector_weights)\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_23771/66897659.py\u001b[0m in \u001b[0;36mget_ps_dict\u001b[0;34m(ds_combined_dets, classes, cls_kbf_config, scale_conf_by_ndets, detector_weights)\u001b[0m\n\u001b[1;32m     24\u001b[0m                                            \u001b[0mradius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls_kbf_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'radius'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                                            \u001b[0mnms_thresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls_kbf_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nms'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                                            weights=None)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# E.g. car,truck,bus,motorcycle,bicycle,pedestrian (id: 1,2,3,4,5,6) -> Veh,Cyc,Ped (id: 1,4,6)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: label_fusion() got an unexpected keyword argument 'weights'"
     ]
    }
   ],
   "source": [
    "# ['Vehicle', 'Vehicle', 'Vehicle', 'Cyclist', 'Cyclist', 'Pedestrian']\n",
    "classes=target_set.dataset_cfg.CLASS_NAMES\n",
    "discard=[4]*6\n",
    "radius=[1,1,1, 0.3,0.3, 0.2]\n",
    "kbf_nms=[0.1,0.1,0.1,0.5,0.5,0.5,0.5]\n",
    "detector_weights = {}\n",
    "detector_weights['heading'] = np.array([1,1,1,1,2,2,2,2,2,2,2,2,1,1,1,1,3,3,3,3,3,3,3,3])\n",
    "min_score = 0.3\n",
    "\n",
    "# confidence scaling\n",
    "scale_conf_by_ndets = True\n",
    "num_boxes_at_unity = int(len(det_annos) * 0.75)\n",
    "max_scale_score = cfg.SELF_TRAIN.SCORE_THRESH + 0.1\n",
    "\n",
    "# Downsample\n",
    "# ds_combined_dets = combined_dets[::3]\n",
    "\n",
    "# Get class specific config\n",
    "cls_kbf_config = {}\n",
    "for enum, cls in enumerate(classes):\n",
    "    if cls in cls_kbf_config.keys():\n",
    "        continue\n",
    "    cls_kbf_config[cls] = {}\n",
    "    cls_kbf_config[cls]['cls_id'] = enum+1 # in OpenPCDet, cls_ids enumerate from 1\n",
    "    cls_kbf_config[cls]['discard'] = discard[enum]\n",
    "    cls_kbf_config[cls]['radius'] = radius[enum]\n",
    "    cls_kbf_config[cls]['nms'] = kbf_nms[enum]\n",
    "\n",
    "ps_dict = get_ps_dict(ds_combined_dets, ['Cyclist'], cls_kbf_config, \n",
    "                      scale_conf_by_ndets=scale_conf_by_ndets, detector_weights=detector_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pcdet.utils import generate_ps_utils \n",
    "# generate_ps_utils.save_data(ps_dict, '/MS3D/tools/cfgs/target_waymo/kbf_combinations', \n",
    "#                             name=f\"kbf_multiclass_exp1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 695/695 [00:00<00:00, 55238.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate fused pred boxes\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset = target_set\n",
    "pred_annos, gt_annos = [], []\n",
    "eval_gt_annos = copy.deepcopy(dataset.infos)\n",
    "for frame_id in tqdm(ps_dict.keys(), total=len(ps_dict.keys())):  \n",
    "    boxes = ps_dict[frame_id]['gt_boxes'].copy()            \n",
    "    boxes[:,:3] -= dataset.dataset_cfg.SHIFT_COOR # just for eval in this notebook\n",
    "    p_anno = {\"frame_id\": frame_id,\n",
    "              \"name\": np.array([dataset.dataset_cfg.CLASS_NAMES[int(abs(box[7]))-1] for box in boxes]),\n",
    "              \"pred_labels\": np.array([abs(box[7]) for box in boxes]),\n",
    "              \"boxes_lidar\": boxes[:,:7],\n",
    "              \"score\": boxes[:,8]}\n",
    "    pred_annos.append(p_anno)\n",
    "    gt_annos.append(eval_gt_annos[dataset.frameid_to_idx[frame_id]]['annos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start the waymo evaluation...\n",
      "Number: (pd, 502597) VS. (gt, 483970)\n",
      "Level 1: 403376, Level2: 80594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 00:01:34.665495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-05-22 00:01:34.665525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n",
      "I0522 00:01:34.744335 18838 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:01:34.744354 18838 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:01:34.912678 18838 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:01:45.571396 18838 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:01:45.975847 18837 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:01:45.975864 18837 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:01:46.132743 18837 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:01:56.293432 18837 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:01:56.700409 18840 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:01:56.700425 18840 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:01:56.866497 18840 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:02:07.028822 18840 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:02:07.434468 18840 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:02:07.434484 18840 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:02:07.524616 18840 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:02:17.961249 18840 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:02:18.391927 18837 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:02:18.391942 18837 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:02:18.494935 18837 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:02:29.419879 18837 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:02:29.883440 18837 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:02:29.883459 18837 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:02:29.986203 18837 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:02:41.404342 18837 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:02:41.850359 18837 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:02:41.850384 18837 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:02:41.965611 18837 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:02:52.702379 18837 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:02:53.149406 18842 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:02:53.149426 18842 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:02:53.325903 18842 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:03:05.348111 18842 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:03:05.761029 18840 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:03:05.761047 18840 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:03:05.851770 18840 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:03:17.488159 18840 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:03:17.970420 18844 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:03:17.970443 18844 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:03:18.137502 18844 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:03:29.705811 18844 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:03:30.199666 18843 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:03:30.199680 18843 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:03:30.383126 18843 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:03:41.983919 18843 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:03:42.409212 18839 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:03:42.409230 18839 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:03:42.571794 18839 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:03:54.454496 18839 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:03:54.982959 18838 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:03:54.982977 18838 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:03:55.091662 18838 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:04:06.571429 18838 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:04:07.018244 18844 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:04:07.018262 18844 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:04:07.126950 18844 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:04:18.701977 18844 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:04:19.122570 18839 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:04:19.122591 18839 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:04:19.230800 18839 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:04:30.094053 18839 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:04:30.624151 18838 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:04:30.624177 18838 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:04:30.764281 18838 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:04:41.376024 18838 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:04:41.828091 18838 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:04:41.828109 18838 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:04:41.918133 18838 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:04:52.940397 18838 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:04:53.443670 18840 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:04:53.443689 18840 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:04:53.548427 18840 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:05:04.898165 18840 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:05:05.396675 18841 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:05:05.396692 18841 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:05:05.578117 18841 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:05:16.040529 18841 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:05:16.498943 18840 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:05:16.498957 18840 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:05:16.592303 18840 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0522 00:05:28.777279 18840 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:05:29.224027 18844 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:05:29.224046 18844 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:05:29.323890 18844 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:05:39.361426 18844 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:05:39.759685 18839 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:05:39.759704 18839 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:05:39.848703 18839 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:05:49.853801 18839 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:05:50.255790 18844 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:05:50.255810 18844 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:05:50.346277 18844 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:06:00.383374 18844 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:06:00.804890 18842 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:06:00.804910 18842 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:06:00.895382 18842 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:06:10.926309 18842 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:06:11.323159 18839 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:06:11.323180 18839 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:06:11.412935 18839 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:06:21.470321 18839 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:06:21.869971 18841 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:06:21.869989 18841 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:06:21.960690 18841 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:06:32.195149 18841 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:06:32.733764 18841 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:06:32.733783 18841 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:06:32.839887 18841 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:06:43.314854 18841 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:06:43.756295 18838 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:06:43.756317 18838 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:06:43.845757 18838 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:06:54.427457 18838 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:06:54.905613 18840 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:06:54.905628 18840 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:06:55.000692 18840 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:07:05.690745 18840 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:07:06.094043 18837 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:07:06.094059 18837 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:07:06.183458 18837 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:07:17.087723 18837 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:07:17.526573 18842 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:07:17.526592 18842 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:07:17.627564 18842 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:07:27.918339 18842 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:07:28.322716 18841 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:07:28.322731 18841 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:07:28.411545 18841 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:07:38.559834 18841 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:07:38.960835 18844 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:07:38.960851 18844 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:07:39.050333 18844 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:07:49.470659 18844 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:07:49.869702 18842 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:07:49.869720 18842 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:07:49.959017 18842 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:08:00.459751 18842 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:08:00.875982 18844 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:08:00.875999 18844 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:08:00.986768 18844 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:08:12.143162 18844 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:08:12.547531 18844 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:08:12.547549 18844 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:08:12.643844 18844 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:08:23.320750 18844 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:08:23.759826 18842 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:08:23.759842 18842 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:08:23.857549 18842 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:08:34.225272 18842 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:08:34.638458 18837 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:08:34.638473 18837 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:08:34.727665 18837 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:08:45.054620 18837 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:08:45.453122 18837 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:08:45.453138 18837 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:08:45.546293 18837 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:08:56.146302 18837 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:08:56.560837 18840 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:08:56.560851 18840 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:08:56.688094 18840 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:09:07.720713 18840 detection_metrics_ops.cc:221] Done with computing detection metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0522 00:09:08.182754 18838 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:09:08.182770 18838 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:09:08.284351 18838 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:09:19.275123 18838 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:09:19.738257 18844 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:09:19.738272 18844 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:09:19.837486 18844 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:09:30.405109 18844 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:09:30.820116 18837 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:09:30.820133 18837 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:09:30.913883 18837 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:09:41.697656 18837 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:09:42.210489 18844 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:09:42.210511 18844 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:09:42.317190 18844 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:09:52.822995 18844 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:09:53.229139 18844 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:09:53.229156 18844 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:09:53.318759 18844 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:10:03.626336 18844 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:10:04.079635 18839 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:10:04.079651 18839 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:10:04.168339 18839 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:10:14.420300 18839 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:10:14.824617 18844 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:10:14.824635 18844 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:10:14.913956 18844 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:10:25.189682 18844 detection_metrics_ops.cc:221] Done with computing detection metrics.\n",
      "I0522 00:10:25.600822 18842 detection_metrics_ops.cc:157] Computing detection metrics for 502597 predicted boxes.\n",
      "I0522 00:10:25.600840 18842 detection_metrics_ops.cc:159] Parsing prediction [502597,7][502597]\n",
      "I0522 00:10:25.691951 18842 detection_metrics_ops.cc:168] Parsing ground truth [483970,7][483970]\n",
      "I0522 00:10:36.345703 18842 detection_metrics_ops.cc:221] Done with computing detection metrics.\n"
     ]
    }
   ],
   "source": [
    "# ap_result_str, ap_dict = dataset.kitti_eval(pred_annos, eval_gt_annos, class_names=['Vehicle'])\n",
    "# ap_result_str, ap_dict = dataset.evaluation(pred_annos, dataset.dataset_cfg.CLASS_NAMES, eval_metric='waymo')\n",
    "from pcdet.datasets.waymo.waymo_eval import OpenPCDetWaymoDetectionMetricsEstimator\n",
    "eval = OpenPCDetWaymoDetectionMetricsEstimator()\n",
    "\n",
    "cls_names = dataset.dataset_cfg.CLASS_NAMES\n",
    "cls_names = ['Vehicle','Pedestrian','Cyclist']\n",
    "ap_dict = eval.waymo_evaluation(\n",
    "    pred_annos, gt_annos, class_name=cls_names,\n",
    "    distance_thresh=1000, fake_gt_infos=dataset.dataset_cfg.get('INFO_WITH_FAKELIDAR', False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOURCE\tTARGET\tMODEL\tVEH_[0,30)_L1/AP\tVEH_[0,30)_L1/APH\tVEH_[0,30)_L2/AP\tVEH_[0,30)_L2/APH\tVEH_[30,50)_L1/AP\tVEH_[30,50)_L1/APH\tVEH_[30,50)_L2/AP\tVEH_[30,50)_L2/APH\tVEH_[50,+inf)_L1/AP\tVEH_[50,+inf)_L1/APH\tVEH_[50,+inf)_L2/AP\tVEH_[50,+inf)_L2/APH\tPED_[0,30)_L1/AP\tPED_[0,30)_L1/APH\tPED_[0,30)_L2/AP\tPED_[0,30)_L2/APH\tPED_[30,50)_L1/AP\tPED_[30,50)_L1/APH\tPED_[30,50)_L2/AP\tPED_[30,50)_L2/APH\tPED_[50,+inf)_L1/AP\tPED_[50,+inf)_L1/APH\tPED_[50,+inf)_L2/AP\tPED_[50,+inf)_L2/APH\tCYC_[0,30)_L1/AP\tCYC_[0,30)_L1/APH\tCYC_[0,30)_L2/AP\tCYC_[0,30)_L2/APH\tCYC_[30,50)_L1/AP\tCYC_[30,50)_L1/APH\tCYC_[30,50)_L2/AP\tCYC_[30,50)_L2/APH\tCYC_[50,+inf)_L1/AP\tCYC_[50,+inf)_L1/APH\tCYC_[50,+inf)_L2/AP\tCYC_[50,+inf)_L2/APH\t\n",
      "\n",
      "NuScenes\tWaymo\tVoxelRCNN\t74.66\t74.20\t72.80\t72.35\t48.30\t47.68\t42.21\t41.66\t25.11\t24.52\t18.12\t17.69\t34.26\t19.34\t31.89\t17.99\t21.69\t12.18\t18.37\t10.31\t11.37\t6.15\t7.80\t4.22\t45.72\t41.31\t44.89\t40.56\t28.48\t23.54\t25.21\t20.84\t14.01\t12.27\t11.94\t10.46\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_print(ap_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lyft_models.uda_pv_rcnn_plusplus_resnet_centerhead.custom190_lyft10xyzt_waymo1xyzt_notta', 'lyft_models.uda_pv_rcnn_plusplus_resnet_centerhead.custom190_lyft10xyzt_waymo1xyzt_rwr', 'lyft_models.uda_pv_rcnn_plusplus_resnet_centerhead.custom190_lyft10xyzt_waymo1xyzt_rwf', 'lyft_models.uda_pv_rcnn_plusplus_resnet_centerhead.custom190_lyft10xyzt_waymo1xyzt_rwf_rwr', 'lyft_models.uda_pv_rcnn_plusplus_resnet_centerhead.custom190_lyft10xyzt_waymo2xyzt_notta', 'lyft_models.uda_pv_rcnn_plusplus_resnet_centerhead.custom190_lyft10xyzt_waymo2xyzt_rwr', 'lyft_models.uda_pv_rcnn_plusplus_resnet_centerhead.custom190_lyft10xyzt_waymo2xyzt_rwf', 'lyft_models.uda_pv_rcnn_plusplus_resnet_centerhead.custom190_lyft10xyzt_waymo2xyzt_rwf_rwr', 'lyft_models.uda_pv_rcnn_plusplus_resnet_centerhead.custom190_lyft10xyzt_waymo4xyzt_notta', 'lyft_models.uda_pv_rcnn_plusplus_resnet_centerhead.custom190_lyft10xyzt_waymo4xyzt_rwr', 'lyft_models.uda_pv_rcnn_plusplus_resnet_centerhead.custom190_lyft10xyzt_waymo4xyzt_rwf', 'lyft_models.uda_pv_rcnn_plusplus_resnet_centerhead.custom190_lyft10xyzt_waymo4xyzt_rwf_rwr'])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det_annos.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 6280/6280 [00:00<00:00, 154300.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate single pred annos\n",
    "baseline = det_annos['lyft_models.uda_pv_rcnn_plusplus_resnet_centerhead.custom190_lyft10xyzt_waymo1xyzt_notta'][::3]\n",
    "cls_names = ['Cyclist']\n",
    "dataset = target_set\n",
    "pred_annos, gt_annos = [], []\n",
    "eval_gt_annos = copy.deepcopy(dataset.infos)\n",
    "for p_anno in tqdm(baseline, total=len(baseline)):  \n",
    "    p_anno['boxes_lidar'][:,:3] -= dataset.dataset_cfg.SHIFT_COOR # just for eval in this notebook\n",
    "    pred_annos.append(p_anno)\n",
    "    gt_annos.append(eval_gt_annos[dataset.frameid_to_idx[p_anno['frame_id']]]['annos'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling by number of detectors\n",
    "\n",
    "This desmos grapher was useful for coming up with below https://www.desmos.com/calculator\n",
    "\n",
    "At the end of the day we just wanted to map one range to another in a non-linear fashion where we can specify how many detections would give a scaling=1; or what the max scaling is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_scaling_coeff(num_boxes, num_boxes_at_unity, eq_type='sqrt', max_scaling=2.0):\n",
    "    \"\"\"\n",
    "    This function returns the scaling coefficient to scale the confidence score based on\n",
    "    the number of boxes proposed for an object. Two scaling equations are provided.\n",
    "    \n",
    "    Note: This might be bad if many detectors detect but wrongly detect -> adjust max_scaling according\n",
    "    \n",
    "    num_boxes (list of ints): number of input boxes for each kbf box fusion\n",
    "    num_boxes_at_unity (int): The point at which the scaling coeff is equal to 1. \n",
    "                        Less than this and coeff < 1; More than this and coeff > 1.\n",
    "    \"\"\"\n",
    "    if eq_type == 'sqrt':\n",
    "        # Non-linear scaling with sqrt(x)        \n",
    "        scaling = (1/np.sqrt(num_boxes_at_unity)) * np.sqrt(num_boxes) \n",
    "        \n",
    "    elif eq_type == 'linear':\n",
    "        scaling = (1/num_boxes_at_unity) * num_boxes\n",
    "        \n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    return np.clip(scaling, a_max=max_scaling, a_min=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8164965809277261, 1.4142135623730951)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set a config where you can enable/disable this\n",
    "def min_boxes_conf_scaling(num_boxes, min_boxes, eq_type='sqrt', max_scaling=2.0):\n",
    "    \"\"\"\n",
    "    For this function, at min_boxes, scaling is 1. We clip if it gets too large.    \n",
    "    Adjustable param: min_boxes\n",
    "    \"\"\"\n",
    "    if eq_type == 'sqrt':\n",
    "        # Non-linear scaling with sqrt(x)        \n",
    "        scaling = (1/np.sqrt(min_boxes)) * np.sqrt(num_boxes) \n",
    "        \n",
    "    elif eq_type == 'linear':\n",
    "        scaling = (1/min_boxes) * num_boxes\n",
    "        \n",
    "    else:\n",
    "        raise notImplementedError\n",
    "        \n",
    "    return np.clip(scaling, a_max=max_scaling, a_min=0)\n",
    "\n",
    "\n",
    "def total_dets_conf_scaling(num_boxes, total_num_detectors, eq_type='sqrt', max_scaling=2.0):\n",
    "    \"\"\"\n",
    "    For this function, at total_num_detectors, scaling is max_scaling. The point where scaling=1\n",
    "    will change according to the total_num_detectors which may not be optimal.\n",
    "    \n",
    "    Adjustable param: total_num_detectors\n",
    "    \"\"\"\n",
    "    if eq_type == 'sqrt':\n",
    "        # Non-linear scaling with sqrt(x)        \n",
    "        scaling = (max_scaling/np.sqrt(total_num_detectors)) * np.sqrt(num_boxes) \n",
    "        \n",
    "    elif eq_type == 'linear':\n",
    "        scaling = (max_scaling/total_num_detectors) * num_boxes\n",
    "        \n",
    "    else:\n",
    "        raise notImplementedError\n",
    "        \n",
    "    return np.clip(scaling, a_max=max_scaling, a_min=0)\n",
    "\n",
    "\n",
    "# min_dets = 20\n",
    "# x = np.arange(0,30)\n",
    "# # y = (1/np.sqrt(min_dets)) * np.sqrt(x) \n",
    "# y = 1/20 * x\n",
    "# plt.plot(x,y)\n",
    "# plt.grid(True)\n",
    "\n",
    "# Non-linear scaling with sqrt(x)\n",
    "# using 2/sqrt(num_det) means that at num_dets, scaling is max_scaling -> But we don't set min_dets\n",
    "# Adjustable param: max_scaling\n",
    "# num_detectors = 24\n",
    "# max_scaling = 2\n",
    "# x = np.arange(0,30)\n",
    "# y = (max_scaling/np.sqrt(num_detectors)) * np.sqrt(x) \n",
    "# plt.plot(x,y)\n",
    "# plt.grid(True)\n",
    "scale1 = total_dets_conf_scaling(1, 6, eq_type='sqrt') # if total detectors is low, then the scaling is jumpy\n",
    "scale2 = min_boxes_conf_scaling(6, 3, eq_type='sqrt') # works better for varying min_boxes\n",
    "scale1, scale2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
